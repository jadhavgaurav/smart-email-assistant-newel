# ğŸ“¬ Smart Email Assistant using ML, GenAI, and Agents

An end-to-end AI-powered assistant that classifies incoming emails, generates automatic responses using an open-source LLM, and escalates low-confidence queries for human review. Built using Python, Streamlit, Ollama (LLM), and Docker.

---

## ğŸš€ Features

- ğŸ“‚ **Email Classification Agent (ML)** â€“ Logistic Regression model trained to classify emails into HR, IT, or Other.
- ğŸ¤– **Response Agent (LLM)** â€“ Uses a local LLM via Ollama (LLaMA3 8B) to generate context-aware replies.
- âš ï¸ **Escalation Agent** â€“ Triggers if classification confidence is low or ambiguous.
- ğŸŒ **Streamlit UI** â€“ Interactive web app for testing and managing emails.
- ğŸ“Š **Logging** â€“ Saves every interaction and optionally uploads to AWS S3.
- ğŸ³ **Dockerized** â€“ Fully containerized for local or cloud deployment.

---

```markdown
## ğŸ§  Agentic Workflow

```mermaid
graph TD
    A[Incoming Email] --> B[Email Classifier (ML)]
    B --> C{Confidence >= 0.6 and Category â‰  Other?}
    C -->|Yes| D[LLM Response Generator]
    C -->|No| E[Escalation Agent]
    D --> F[Return Response]
    E --> F
```
---

## ğŸ“¦ Folder Structure

```
smart-email-assistant/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ email_classifier.py
â”‚   â”‚   â”œâ”€â”€ response_generator.py / crewai_response_agent.py
â”‚   â”‚   â””â”€â”€ escalation_agent.py
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â””â”€â”€ streamlit_ui.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ emails.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_cleaning.ipynb
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ history.csv
â”œâ”€â”€ models/
â”‚   â””â”€â”€ model.pkl
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š ML Model Details

- Model: `RandomForestClassifier`
- Dataset: 900+
- Classes: HR, IT, Other
- Metrics:
  - Accuracy: ~94%
  - Confusion Matrix & classification report included in notebook
- Confidence Threshold: `0.6`

---

## ğŸ¤– LLM Integration (Ollama)

- Model: `llama3:8b-instruct-q4_K_M`
- Backend: `Ollama` running on `localhost:11434`
- Framework: `LangChain + langchain-ollama`
- Base Prompt per category:
  - HR: "You are an HR assistant. Reply professionally..."
  - IT: "You are an IT assistant. Help with this issue..."

---

## ğŸŒ Streamlit UI

### Features
- Input email content
- Shows classification, confidence, action
- Returns LLM-generated reply or escalation
- Logs all results to CSV (and optionally uploads to S3)

### Run Locally
```bash
poetry install
poetry run streamlit run app/streamlit_ui.py
```

### Run with Docker
```bash
docker pull jadhavgaurav007/smart-email-assistant
docker run -p 8501:8501 jadhavgaurav007/smart-email-assistant
```
> Make sure `ollama serve` is running on host

---

## ğŸ³ Docker Deployment

### Build Locally
```bash
docker build -t smart-email-assistant .
```

### Tag & Push
```bash
docker tag smart-email-assistant jadhavgaurav007/smart-email-assistant
docker push jadhavgaurav007/smart-email-assistant
```

---

## ğŸ’¡ Author
**Gaurav Vijay Jadhav**  
AI Engineer | Thane, Maharashtra  
ğŸ“§ gaurav.vjadhav01@gmail.com